{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook I will test how to implement a function that will take a csv and create a partitioned parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing partition locally to see if it works with pyspark\n",
    "\n",
    "cleaning my csv file with Csv class but changing the class so it doesnt convert to parquet. This is because its better to write the partitions directly to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvCleaner:\n",
    "    @staticmethod\n",
    "    def timestamp_clean(df, col_name):\n",
    "        # convert the column to numeric with any errors(for example strings or letter) to NaN\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors=\"coerce\")\n",
    "        \n",
    "        df.dropna(subset=[col_name], inplace=True)\n",
    "\n",
    "        # Calculate the initial number of rows\n",
    "        initial_rows = df.shape[0]\n",
    "        \n",
    "        #Filter out rows with \"Timestamp\" values not containing 10 digits\n",
    "        df = df[df[col_name].apply(lambda x: len(str(int(x))) == 10)]\n",
    "\n",
    "        #calculate how many rows removed\n",
    "        rows_removed = initial_rows - df.shape[0]\n",
    "\n",
    "        # Convert the Unix timestamp to datetime with seconds\n",
    "        df[col_name] = pd.to_datetime(df[col_name], unit=\"s\")\n",
    "\n",
    "        # Sort the DataFrame by the timestamp column\n",
    "        df = df.sort_values(by=col_name)\n",
    "\n",
    "        return df, rows_removed\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_columns(df, col_name, low, high):\n",
    "    \n",
    "        # Convert column to numeric, making errors to Nan instead\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors=\"coerce\")\n",
    "\n",
    "        # Calculate the initial number of rows\n",
    "        initial_rows = df.shape[0]\n",
    "\n",
    "        df.loc[~df[col_name].between(low, high), col_name] = float('nan')\n",
    "\n",
    "        # Calculate the number of rows removed\n",
    "        rows_removed = initial_rows - df.shape[0]\n",
    "\n",
    "        #df[col_name] = df[col_name].interpolate()\n",
    "\n",
    "        return df, rows_removed\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_file(csv_file):\n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "        total_rows_removed = 0\n",
    "\n",
    "        # Clean the DataFrame\n",
    "        for col in df.columns:\n",
    "            if \"Timestamp\" in col:\n",
    "                df, rows_removed = CsvCleaner.timestamp_clean(df, col)\n",
    "                total_rows_removed += rows_removed\n",
    "            \n",
    "            if \"speed_over_ground\" in col:\n",
    "                low = 0\n",
    "                high = 100\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df, col, low, high)\n",
    "                total_rows_removed += rows_removed\n",
    "            \n",
    "            if \"Longitude\" in col:\n",
    "                low = -180\n",
    "                high = 180\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df, col, low, high)\n",
    "                total_rows_removed += rows_removed\n",
    "\n",
    "            if \"Latitude\" in col:\n",
    "                low = -90\n",
    "                high = 90\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df, col, low, high)\n",
    "                total_rows_removed += rows_removed\n",
    "\n",
    "            if \"engine_fuel_rate\" in col:\n",
    "                low = 0\n",
    "                high = 100\n",
    "                df,rows_removed = CsvCleaner.clean_columns(df, col, low, high)\n",
    "                total_rows_removed += rows_removed\n",
    "\n",
    "        output_dir = os.path.dirname(csv_file)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        file_name_without_extension, extension = os.path.splitext(file_name)\n",
    "        cleaned_csv_file = os.path.join(output_dir, file_name_without_extension + \"_cleaned.csv\")\n",
    "\n",
    "        df.to_csv(cleaned_csv_file, index=False)\n",
    "\n",
    "        print(f\"Total rows removed: {total_rows_removed}\")\n",
    "\n",
    "        return cleaned_csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_1 = \"../src/Data/vessel1_dummy_boat_data.csv\"\n",
    "vessel_2 = \"../src/Data/vessel2_dummy_boat_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows removed: 5\n",
      "Total rows removed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1319/2019830326.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = pd.to_datetime(df[col_name], unit=\"s\")\n",
      "/tmp/ipykernel_1319/2019830326.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_name] = pd.to_datetime(df[col_name], unit=\"s\")\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of CsvCleaner\n",
    "cleaner = CsvCleaner()\n",
    "\n",
    "# Clean the CSV file\n",
    "vessel_1_csv_file_path = cleaner.clean_file(vessel_1)\n",
    "vessel_2_csv_file_path = cleaner.clean_file(vessel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../src/Data/vessel1_dummy_boat_data_cleaned.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
