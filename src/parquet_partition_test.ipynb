{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook I will test how to implement a function that will take a csv and create a partitioned parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing partition locally to see if it works with pyspark\n",
    "\n",
    "cleaning my csv file with Csv class but changing the class so it doesnt convert to parquet. This is because its better to write the partitions directly to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvCleaner:\n",
    "    @staticmethod\n",
    "    def timestamp_clean(df:pd.DataFrame, col_name:str) -> tuple[pd.DataFrame,int]:\n",
    "        \"\"\"\n",
    "        Cleans the DataFrame by converting the specified column to numeric, \n",
    "        filtering out rows with invalid timestamps, converting timestamps to datetime, \n",
    "        sorting by timestamp, and returning the cleaned DataFrame along with \n",
    "        the number of rows removed.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to be cleaned.\n",
    "            col_name (str): The name of the column containing timestamps.\n",
    "\n",
    "        Returns:\n",
    "            tuple[pd.DataFrame, int]: A tuple containing the cleaned DataFrame \n",
    "            and the number of rows removed.\n",
    "        \"\"\"\n",
    "        # convert the column to numeric with any errors(for example strings or letter) to NaN\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors=\"coerce\")\n",
    "        \n",
    "        df.dropna(subset=[col_name], inplace=True)\n",
    "\n",
    "        # Calculate the initial number of rows\n",
    "        initial_rows = df.shape[0]\n",
    "        \n",
    "        #Filter out rows with \"Timestamp\" values not containing 10 digits\n",
    "        df = df[df[col_name].apply(lambda x: len(str(int(x))) == 10)]\n",
    "\n",
    "        #calculate how many rows removed\n",
    "        rows_removed = initial_rows - df.shape[0]\n",
    "\n",
    "        # Convert the Unix timestamp to datetime with seconds\n",
    "        df[col_name] = pd.to_datetime(df[col_name], unit=\"s\")\n",
    "\n",
    "        # Sort the DataFrame by the timestamp column\n",
    "        df = df.sort_values(by=col_name)\n",
    "\n",
    "        return df, rows_removed\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_columns(df: pd.DataFrame, col_name: str, low: float, high: float) -> tuple[pd.DataFrame, int]:\n",
    "        \"\"\"\n",
    "        Cleans the specified column in the DataFrame by converting it to numeric, \n",
    "        filtering out values that are not within the specified range, \n",
    "        and returning the cleaned DataFrame along with the number of rows removed.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to be cleaned.\n",
    "            col_name (str): The name of the column to be cleaned.\n",
    "            low (float): The lower bound of the acceptable range.\n",
    "            high (float): The upper bound of the acceptable range.\n",
    "\n",
    "        Returns:\n",
    "            tuple[pd.DataFrame, int]: A tuple containing the cleaned DataFrame \n",
    "            and the number of rows removed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert column to numeric, making errors to Nan instead\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors=\"coerce\")\n",
    "\n",
    "        # Calculate the initial number of rows\n",
    "        initial_rows = df.shape[0]\n",
    "\n",
    "        df.loc[~df[col_name].between(low, high), col_name] = float('nan')\n",
    "\n",
    "        # Calculate the number of rows removed\n",
    "        rows_removed = initial_rows - df.shape[0]\n",
    "\n",
    "        #df[col_name] = df[col_name].interpolate()\n",
    "\n",
    "        return df, rows_removed\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_file(df: pd.DataFrame, file_key: str) ->str:\n",
    "        \"\"\"\n",
    "        Cleans the DataFrame by applying specific cleaning operations based on column names,\n",
    "        saves the cleaned DataFrame as a Parquet file, and returns the path to the cleaned Parquet file.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to be cleaned.\n",
    "            file_key (str): The key of the file.\n",
    "\n",
    "        Returns:\n",
    "            str: The path to the cleaned Parquet file.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_rows_removed = 0\n",
    "\n",
    "        # Clean the DataFrame\n",
    "        for col in df.columns:\n",
    "            if \"Timestamp\" in col:\n",
    "                df, rows_removed = CsvCleaner.timestamp_clean(df.copy(), col)\n",
    "                df[col] = pd.to_datetime(df[col])\n",
    "                total_rows_removed += rows_removed\n",
    "            \n",
    "            if \"speed_over_ground\" in col:\n",
    "                low = 0\n",
    "                high = 100\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df.copy(), col, low, high)\n",
    "                df[col] = df[col].astype(float)\n",
    "                total_rows_removed += rows_removed\n",
    "            \n",
    "            if \"Longitude\" in col:\n",
    "                low = -180\n",
    "                high = 180\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df.copy(), col, low, high)\n",
    "                df[col] = df[col].astype(float)\n",
    "                total_rows_removed += rows_removed\n",
    "\n",
    "            if \"Latitude\" in col:\n",
    "                low = -90\n",
    "                high = 90\n",
    "                df, rows_removed = CsvCleaner.clean_columns(df.copy(), col, low, high)\n",
    "                df[col] = df[col].astype(float)\n",
    "                total_rows_removed += rows_removed\n",
    "\n",
    "            if \"engine_fuel_rate\" in col:\n",
    "                low = 0\n",
    "                high = 100\n",
    "                df,rows_removed = CsvCleaner.clean_columns(df.copy(), col, low, high)\n",
    "                df[col] = df[col].astype(float)\n",
    "                total_rows_removed += rows_removed\n",
    "        \n",
    "            \n",
    "        # Resample the DataFrame\n",
    "        df.set_index('Timestamp', inplace=True)\n",
    "        df = df.resample('10s').mean()  # No fillna(0) here\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Save as partitioned Parquet file\n",
    "        parquet_file = CsvCleaner._partition_and_save(df, file_key)\n",
    "        \n",
    "        print(f\"Total rows removed: {total_rows_removed}\")\n",
    "\n",
    "\n",
    "        return parquet_file, file_key\n",
    "    \n",
    "    @staticmethod\n",
    "    def _partition_and_save(df: pd.DataFrame, file_key: str) -> str:\n",
    "        \"\"\"\n",
    "        Partitions and saves the cleaned DataFrame as a Parquet file.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The DataFrame to be saved.\n",
    "            file_key (str): The key of the file.\n",
    "\n",
    "        Returns:    \n",
    "            str: The path to the saved Parquet file.\n",
    "        \"\"\"\n",
    "        # Extract vessel name from the file key\n",
    "        vessel_name = file_key.split('_')[0] # use path lib here for realdata\n",
    "\n",
    "        # Partition by timestamp and vessel name\n",
    "        df[\"year\"] = df[\"Timestamp\"].dt.year.astype(str)\n",
    "        df[\"month\"] = df[\"Timestamp\"].dt.month.astype(str).str.zfill(2)\n",
    "        df[\"day\"] = df[\"Timestamp\"].dt.day.astype(str).str.zfill(2)\n",
    "        df[\"vessel\"] = vessel_name\n",
    "\n",
    "        # Define the partition keys\n",
    "        partition_cols = [\"vessel\", \"year\", \"month\", \"day\"]\n",
    "\n",
    "        # Save as partitioned Parquet file\n",
    "        cleaned_parquet_file = f\"../src/Data/partitioned_parquets/{file_key}.parquet\" # change this to temp file\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        # root path need to go to s3\n",
    "        pq.write_to_dataset(table, root_path=\"../src/Data/partitioned_parquets/\", partition_cols=partition_cols)\n",
    "\n",
    "        return cleaned_parquet_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = \"vessel1_dummy_boat_data.csv\"\n",
    "df = pd.read_csv(\"../src/Data/vessel1_dummy_boat_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>speed_over_ground</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>engine_fuel_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1675119600</td>\n",
       "      <td>3.08</td>\n",
       "      <td>-119.605263</td>\n",
       "      <td>35.162237</td>\n",
       "      <td>14.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1675119601</td>\n",
       "      <td>4.11</td>\n",
       "      <td>-118.857776</td>\n",
       "      <td>35.228734</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675119602</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-118.110278</td>\n",
       "      <td>35.295227</td>\n",
       "      <td>20.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1675119603</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-117.362786</td>\n",
       "      <td>35.361725</td>\n",
       "      <td>17.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1675119604</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>-116.615295</td>\n",
       "      <td>35.428215</td>\n",
       "      <td>17.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp speed_over_ground    Longitude   Latitude engine_fuel_rate\n",
       "0  1675119600              3.08  -119.605263  35.162237            14.92\n",
       "1  1675119601              4.11  -118.857776  35.228734            21.02\n",
       "2  1675119602              4.04  -118.110278  35.295227            20.53\n",
       "3  1675119603               3.5  -117.362786  35.361725            17.21\n",
       "4  1675119604             ERROR  -116.615295  35.428215            17.38"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Timestamp          990 non-null    object\n",
      " 1   speed_over_ground  990 non-null    object\n",
      " 2   Longitude          990 non-null    object\n",
      " 3   Latitude           990 non-null    object\n",
      " 4   engine_fuel_rate   990 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows removed: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55675/3390757632.py:127: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  df = df.resample('10S').mean()  # No fillna(0) here\n"
     ]
    }
   ],
   "source": [
    "cleaned_parquet_file = CsvCleaner.clean_file(df, file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x7f276b59eb10>\n",
       "  created_by: parquet-cpp-arrow version 15.0.0\n",
       "  num_columns: 5\n",
       "  num_rows: 100\n",
       "  num_row_groups: 1\n",
       "  format_version: 2.6\n",
       "  serialized_size: 4540"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pq.read_metadata(\"../src/Data/partitioned_parquets/vessel=vessel1/year=2023/month=01/day=30/9da8e6605723499d97fa3e8a292317e9-0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>speed_over_ground</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>engine_fuel_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-30 23:00:00</td>\n",
       "      <td>3.822222</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>35.461460</td>\n",
       "      <td>18.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-30 23:00:10</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>-108.766642</td>\n",
       "      <td>36.159641</td>\n",
       "      <td>22.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-30 23:00:20</td>\n",
       "      <td>5.412000</td>\n",
       "      <td>-101.291727</td>\n",
       "      <td>36.795025</td>\n",
       "      <td>27.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-30 23:00:30</td>\n",
       "      <td>14.632222</td>\n",
       "      <td>-93.941394</td>\n",
       "      <td>37.445181</td>\n",
       "      <td>30.208889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30 23:00:40</td>\n",
       "      <td>7.013333</td>\n",
       "      <td>-82.812080</td>\n",
       "      <td>38.435198</td>\n",
       "      <td>35.202222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  speed_over_ground   Longitude   Latitude  \\\n",
       "0 2023-01-30 23:00:00           3.822222 -116.241552  35.461460   \n",
       "1 2023-01-30 23:00:10           4.550000 -108.766642  36.159641   \n",
       "2 2023-01-30 23:00:20           5.412000 -101.291727  36.795025   \n",
       "3 2023-01-30 23:00:30          14.632222  -93.941394  37.445181   \n",
       "4 2023-01-30 23:00:40           7.013333  -82.812080  38.435198   \n",
       "\n",
       "   engine_fuel_rate  \n",
       "0         18.863000  \n",
       "1         22.651000  \n",
       "2         27.070000  \n",
       "3         30.208889  \n",
       "4         35.202222  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pq.read_table(\"../src/Data/partitioned_parquets/vessel=vessel1/year=2023/month=01/day=30/9da8e6605723499d97fa3e8a292317e9-0.parquet\")\n",
    "\n",
    "df_parquet = table.to_pandas()\n",
    "\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key_2 = \"vessel2_dummy_boat_data.csv\"\n",
    "df_2 = pd.read_csv(\"../src/Data/vessel2_dummy_boat_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows removed: 5\n"
     ]
    }
   ],
   "source": [
    "cleaned_parquet_file = CsvCleaner.clean_file(df_2, file_key_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>speed_over_ground</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>engine_fuel_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-30 23:00:00</td>\n",
       "      <td>3.822222</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>35.461460</td>\n",
       "      <td>18.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-30 23:00:10</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>-108.766642</td>\n",
       "      <td>36.159641</td>\n",
       "      <td>22.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-30 23:00:20</td>\n",
       "      <td>5.412000</td>\n",
       "      <td>-101.291727</td>\n",
       "      <td>36.795025</td>\n",
       "      <td>27.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-30 23:00:30</td>\n",
       "      <td>14.632222</td>\n",
       "      <td>-93.941394</td>\n",
       "      <td>37.445181</td>\n",
       "      <td>30.208889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30 23:00:40</td>\n",
       "      <td>7.013333</td>\n",
       "      <td>-82.812080</td>\n",
       "      <td>38.435198</td>\n",
       "      <td>35.202222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  speed_over_ground   Longitude   Latitude  \\\n",
       "0 2023-01-30 23:00:00           3.822222 -116.241552  35.461460   \n",
       "1 2023-01-30 23:00:10           4.550000 -108.766642  36.159641   \n",
       "2 2023-01-30 23:00:20           5.412000 -101.291727  36.795025   \n",
       "3 2023-01-30 23:00:30          14.632222  -93.941394  37.445181   \n",
       "4 2023-01-30 23:00:40           7.013333  -82.812080  38.435198   \n",
       "\n",
       "   engine_fuel_rate  \n",
       "0         18.863000  \n",
       "1         22.651000  \n",
       "2         27.070000  \n",
       "3         30.208889  \n",
       "4         35.202222  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pq.read_table(\"../src/Data/partitioned_parquets/vessel=vessel2/year=2023/month=01/day=30/a664216dec3f4e2787509cdbfed1a2ba-0.parquet\")\n",
    "\n",
    "df_parquet = table.to_pandas()\n",
    "\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing keys from .env file\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_REGION_NAME = os.getenv(\"AWS_REGION_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Timestamp  speed_over_ground   Longitude   Latitude  \\\n",
      "0  2023-01-30 23:00:00           3.822222 -116.241552  35.461460   \n",
      "1  2023-01-30 23:00:10           4.550000 -108.766642  36.159641   \n",
      "2  2023-01-30 23:00:20           5.412000 -101.291727  36.795025   \n",
      "3  2023-01-30 23:00:30          14.632222  -93.941394  37.445181   \n",
      "4  2023-01-30 23:00:40           7.013333  -82.812080  38.435198   \n",
      "..                 ...                ...         ...        ...   \n",
      "95 2023-01-30 23:15:50          13.820000   84.295656  28.838670   \n",
      "96 2023-01-30 23:16:00          14.364000   85.556275  34.389400   \n",
      "97 2023-01-30 23:16:10          14.905000   86.849217  39.924228   \n",
      "98 2023-01-30 23:16:20          15.516667   88.106244  45.944147   \n",
      "99 2023-01-30 23:16:30          16.058889   89.435102  51.502830   \n",
      "\n",
      "    engine_fuel_rate   vessel  \n",
      "0          18.863000  vessel1  \n",
      "1          22.651000  vessel1  \n",
      "2          27.070000  vessel1  \n",
      "3          30.208889  vessel1  \n",
      "4          35.202222  vessel1  \n",
      "..               ...      ...  \n",
      "95         68.787143  vessel1  \n",
      "96         71.778000  vessel1  \n",
      "97         74.496000  vessel1  \n",
      "98         77.652222  vessel1  \n",
      "99         80.608000  vessel1  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# checking if lambda function works\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3', \n",
    "                  aws_access_key_id=AWS_ACCESS_KEY_ID, \n",
    "                  aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n",
    "                  region_name=AWS_REGION_NAME)\n",
    "\n",
    "# Read CSV file from S3 into a Pandas DataFrame\n",
    "try:\n",
    "    # Use 's3.get_object' to get the object and 'pd.read_csv' to read it into a DataFrame\n",
    "    obj = s3.get_object(Bucket=\"new-parquet-files\", Key=\"vessel1/year=2023/month=01/day=30/vessel1_dummy_boat_data.parquet\")\n",
    "\n",
    "    obj_bytes = obj[\"Body\"].read()\n",
    "\n",
    "    obj_bytes_io = BytesIO(obj_bytes)\n",
    "\n",
    "    df = pd.read_parquet(obj_bytes_io)\n",
    "    print(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
